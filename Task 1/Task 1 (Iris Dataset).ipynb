{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019ba8e1",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ“Œ Task 1: Exploring and Visualizing the Iris Dataset\n",
    "\n",
    "## ğŸ“ Introduction and Problem Statement\n",
    "The Iris dataset is one of the most well-known datasets in machine learning and statistics.\n",
    "It contains 150 observations of iris flowers from three different species (setosa, versicolor, virginica).\n",
    "Each observation includes four features: sepal length, sepal width, petal length, and petal width.\n",
    "The objective of this task is to explore the dataset, visualize relationships, clean if needed,\n",
    "and build a classification model to predict the species of the flower.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab81658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ğŸ“š Import Required Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# ğŸ“¥ Load the Iris Dataset\n",
    "df = sns.load_dataset(\"iris\")\n",
    "\n",
    "# ğŸ“„ Display Basic Dataset Information\n",
    "print(\"âœ… Shape of the dataset:\", df.shape)\n",
    "print(\"âœ… Column names:\", df.columns.tolist())\n",
    "print(\"\\nğŸ”¹ First 5 rows:\\n\", df.head())\n",
    "\n",
    "# ğŸ” Check for Missing Values\n",
    "print(\"\\nğŸ” Missing values in each column:\\n\", df.isnull().sum())\n",
    "\n",
    "# ğŸ“Š Summary Statistics of the Dataset\n",
    "print(\"\\nğŸ“Š Statistical Summary:\\n\", df.describe())\n",
    "\n",
    "# ğŸ“ˆ Exploratory Data Analysis (EDA)\n",
    "\n",
    "# ğŸ”¹ Pairplot to visualize relationships between features\n",
    "sns.pairplot(df, hue='species')\n",
    "plt.suptitle('ğŸ” Pairplot: Feature Relationships in Iris Dataset', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# ğŸ”¹ Histograms to examine feature distributions\n",
    "df.hist(figsize=(10, 8), bins=15, edgecolor='black')\n",
    "plt.suptitle('ğŸ“Š Histograms of Iris Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ğŸ”¹ Box plots to detect outliers and compare spread\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, column in enumerate(df.columns[:-1], 1):  # Exclude 'species' column\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.boxplot(x='species', y=column, data=df)\n",
    "    plt.title(f'ğŸ“¦ Box Plot of {column} by Species')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ğŸ¤– Model Training and Evaluation\n",
    "\n",
    "# ğŸ”¹ Define Features and Target\n",
    "X = df.drop('species', axis=1)\n",
    "y = df['species']\n",
    "\n",
    "# ğŸ”¹ Split Dataset into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ğŸ”¹ Initialize and Train Logistic Regression Model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ğŸ”¹ Make Predictions on Test Set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ğŸ“ Evaluate Model Performance\n",
    "print(\"\\nâœ… Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nğŸ§¾ Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nğŸ“‰ Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613c7ae6",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ“Œ Conclusion\n",
    "The Iris dataset shows clear separation between the three species based on petal measurements.\n",
    "The Logistic Regression model achieved high accuracy, indicating good performance.\n",
    "Petal length and width are especially strong features for classification.\n",
    "Further improvements can be made using more complex models like SVM or Random Forest.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
